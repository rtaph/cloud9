{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 7: Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code below is referenced from Lecture_1_2.ipynb provided by Gittu George for DSCI 525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from memory_profiler import memory_usage\n",
    "from os import listdir\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshareairline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory if missing\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# download missing files\n",
    "files_to_dl = [\"data.zip\"]\n",
    "for item in filter(lambda x: x['name'] in files_to_dl, files):\n",
    "    filename = os.path.join(output_directory, item[\"name\"])\n",
    "    if not os.path.isfile(filename):\n",
    "        urlretrieve(item[\"download_url\"], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all CSVs\n",
    "csvs = glob.glob(output_directory + '*.csv')\n",
    "\n",
    "# As per Tom's guidance, we can exclude the annoying CSV that is formatted differently\n",
    "csvs = [x for x in csvs if \"observed\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 107.03 MiB, increment: 6.53 MiB\n",
      "CPU times: user 83.8 ms, sys: 38.2 ms, total: 122 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# define a parser to extract the model name\n",
    "def parser(path):\n",
    "    file = os.path.split(path)[1]\n",
    "    return file.split('_daily')[0]\n",
    "\n",
    "# read-in with dask\n",
    "dat = dd.read_csv(csvs, include_path_column = \"model\",\n",
    "                  converters = {\"model\": parser})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 374.64 MiB, increment: 267.60 MiB\n",
      "CPU times: user 659 ms, sys: 153 ms, total: 813 ms\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3197.69 MiB, increment: 2823.05 MiB\n",
      "CPU times: user 1min 13s, sys: 13.3 s, total: 1min 27s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "len(dat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model      mean       std\n",
      "0      MPI-ESM1-2-HR  0.995569  4.083814\n",
      "1      MPI-ESM1-2-LR  1.074308  3.911700\n",
      "2          KIOST-ESM  1.102353  3.852051\n",
      "3         MRI-ESM2-0  1.368030  4.517987\n",
      "4           GFDL-CM4  1.414485  5.024926\n",
      "5   EC-Earth3-Veg-LR  1.516258  4.714335\n",
      "6    MPI-ESM-1-2-HAM  1.610720  4.885519\n",
      "7              NESM3  1.621936  4.971972\n",
      "8        FGOALS-f3-L  1.627373  5.747396\n",
      "9         ACCESS-CM2  1.787025  5.914188\n",
      "10          BCC-ESM1  1.811032  5.358361\n",
      "11           CanESM5  1.894328  5.835787\n",
      "12       BCC-CSM2-MR  1.951832  6.200969\n",
      "13    AWI-ESM-1-1-LR  2.026071  5.321889\n",
      "14         FGOALS-g3  2.156419  6.015488\n",
      "15       SAM0-UNICON  2.169676  6.383241\n",
      "16     ACCESS-ESM1-5  2.217501  6.422397\n",
      "17           TaiESM1  2.224576  5.886578\n",
      "18        NorESM2-LM  2.230799  5.681562\n",
      "19        NorESM2-MM  2.232966  6.151688\n",
      "20         CMCC-ESM2  2.266125  5.538429\n",
      "21      CMCC-CM2-HR4  2.279350  5.629965\n",
      "22            MIROC6  2.301662  6.393745\n",
      "23      CMCC-CM2-SR5  2.383389  5.895950\n",
      "24         INM-CM5-0  2.669012  6.534084\n",
      "25         INM-CM4-8  2.811463  6.266301\n",
      "26         GFDL-ESM4       NaN       NaN\n",
      "peak memory: 3465.90 MiB, increment: 391.36 MiB\n",
      "CPU times: user 2min 33s, sys: 26 s, total: 2min 59s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "res = (dat\n",
    "       .groupby('model')['rain (mm/day)']\n",
    "       .agg([\"mean\", \"std\"])\n",
    "       .sort_values(\"mean\")\n",
    "       .reset_index()\n",
    "       .compute()\n",
    "      )\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
