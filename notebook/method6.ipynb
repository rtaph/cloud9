{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 6: Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code below is referenced from Lecture_1_2.ipynb provided by Gittu George for DSCI 525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from memory_profiler import memory_usage\n",
    "from os import listdir\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshareairline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory if missing\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# download missing files\n",
    "files_to_dl = [\"data.zip\"]\n",
    "for item in filter(lambda x: x['name'] in files_to_dl, files):\n",
    "    filename = os.path.join(output_directory, item[\"name\"])\n",
    "    if not os.path.isfile(filename):\n",
    "        urlretrieve(item[\"download_url\"], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all CSVs\n",
    "csvs = glob.glob(output_directory + '*.csv')\n",
    "\n",
    "# As per Tom's guidance, we can exclude the annoying CSV that is formatted differently\n",
    "csvs = [x for x in csvs if \"observed\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dtypes\n",
    "colspec = {\"time\": \"str\",\n",
    "           \"lat_min\": np.float32,\n",
    "           \"lat_max\": np.float32,\n",
    "           \"lon_min\": np.float32,\n",
    "           \"lon_max\": np.float32,\n",
    "           \"rain (mm/day)\": np.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = [\"time\", \"rain (mm/day)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 12340.41 MiB, increment: 12238.98 MiB\n",
      "CPU times: user 1min 18s, sys: 30.2 s, total: 1min 48s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "dat = pd.DataFrame()\n",
    "for file in csvs:\n",
    "    model = file.split('_daily')[0]\n",
    "    for chunk in pd.read_csv(file, dtype=colspec, parse_dates=[\"time\"], usecols=usecols,\n",
    "                             chunksize=1_000_000):\n",
    "        chunk['model'] = model\n",
    "        dat = pd.concat([dat, chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>figshareairline/MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>figshareairline/MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>figshareairline/MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>figshareairline/MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>figshareairline/MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  rain (mm/day)                            model\n",
       "0 1889-01-01 12:00:00   4.244226e-13  figshareairline/MPI-ESM-1-2-HAM\n",
       "1 1889-01-02 12:00:00   4.217326e-13  figshareairline/MPI-ESM-1-2-HAM\n",
       "2 1889-01-03 12:00:00   4.498125e-13  figshareairline/MPI-ESM-1-2-HAM\n",
       "3 1889-01-04 12:00:00   4.251282e-13  figshareairline/MPI-ESM-1-2-HAM\n",
       "4 1889-01-05 12:00:00   4.270161e-13  figshareairline/MPI-ESM-1-2-HAM"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
